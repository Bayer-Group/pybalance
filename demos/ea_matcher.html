<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Genetic Matcher &mdash; PyBalance</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=f6245a2f"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Constraint Satisfaction Matcher" href="lp_matcher.html" />
    <link rel="prev" title="Propensity Score Matcher" href="ps_matcher.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Population Matching
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../00_introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_installation.html">Installation instructions</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../02_demos.html">Demos</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="matching_data.html">Matching Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="ps_matcher.html">Propensity Score Matcher</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Genetic Matcher</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Optimize-Beta-(Mean-Absolute-SMD)">Optimize Beta (Mean Absolute SMD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Optimize-Beta^2">Optimize Beta^2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Optimize-Gamma-(Area-Between-CDFs)">Optimize Gamma (Area Between CDFs)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lp_matcher.html">Constraint Satisfaction Matcher</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../03_api.html">API documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">License &amp; Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../04_license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_help.html">Help</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Population Matching</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../02_demos.html">Demos</a></li>
      <li class="breadcrumb-item active">Genetic Matcher</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/demos/ea_matcher.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Genetic-Matcher">
<h1>Genetic Matcher<a class="headerlink" href="#Genetic-Matcher" title="Permalink to this heading"></a></h1>
<p>The GeneticMatcher can be used to optimize any function of the baseline covariates, both linear and non-linear. In this demo notebook, we show how to call the matcher in the PyBalance library, including an example of a non-linear balance function.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(levelname)-4s</span><span class="s2"> [</span><span class="si">%(filename)s</span><span class="s2">:</span><span class="si">%(lineno)d</span><span class="s2">] </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="o">=</span><span class="s1">&#39;INFO&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pybalance.sim</span> <span class="kn">import</span> <span class="n">generate_toy_dataset</span>
<span class="kn">from</span> <span class="nn">pybalance.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BetaBalance</span><span class="p">,</span>
    <span class="n">BetaSquaredBalance</span><span class="p">,</span>
    <span class="n">BetaXBalance</span><span class="p">,</span>
    <span class="n">BetaMaxBalance</span><span class="p">,</span>
    <span class="n">GammaBalance</span><span class="p">,</span>
    <span class="n">GammaSquaredBalance</span><span class="p">,</span>
    <span class="n">GammaXBalance</span><span class="p">,</span>
    <span class="n">GammaXTreeBalance</span><span class="p">,</span>
    <span class="n">MatchingData</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pybalance.genetic</span> <span class="kn">import</span> <span class="n">GeneticMatcher</span><span class="p">,</span> <span class="n">get_global_defaults</span>
<span class="kn">from</span> <span class="nn">pybalance.visualization</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">plot_numeric_features</span><span class="p">,</span>
    <span class="n">plot_categoric_features</span><span class="p">,</span>
    <span class="n">plot_binary_features</span><span class="p">,</span>
    <span class="n">plot_per_feature_loss</span><span class="p">,</span>
    <span class="n">plot_joint_numeric_distributions</span>
<span class="p">)</span>

<span class="n">time_limit</span> <span class="o">=</span> <span class="mi">300</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [__init__.py:13] Loaded pybalance version 0.1.0.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">generate_toy_dataset</span><span class="p">()</span>
<span class="n">m</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
        <b>Headers Numeric: </b><br>
        ['age', 'height', 'weight']<br><br>
        <b>Headers Categoric: </b><br>
        ['gender', 'haircolor', 'country', 'binary_0', 'binary_1', 'binary_2', 'binary_3'] <br><br>
        <b>Populations</b> <br>
        ['pool', 'target'] <br>
        <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>height</th>
      <th>weight</th>
      <th>gender</th>
      <th>haircolor</th>
      <th>country</th>
      <th>population</th>
      <th>binary_0</th>
      <th>binary_1</th>
      <th>binary_2</th>
      <th>binary_3</th>
      <th>patient_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>62.511573</td>
      <td>190.229250</td>
      <td>105.165097</td>
      <td>0.0</td>
      <td>2</td>
      <td>3</td>
      <td>pool</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>68.505065</td>
      <td>161.121236</td>
      <td>95.001474</td>
      <td>0.0</td>
      <td>1</td>
      <td>1</td>
      <td>pool</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>50.071384</td>
      <td>162.325356</td>
      <td>84.290576</td>
      <td>1.0</td>
      <td>0</td>
      <td>5</td>
      <td>pool</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>44.423692</td>
      <td>150.948096</td>
      <td>82.031381</td>
      <td>1.0</td>
      <td>2</td>
      <td>2</td>
      <td>pool</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41.695052</td>
      <td>132.952651</td>
      <td>54.857540</td>
      <td>0.0</td>
      <td>1</td>
      <td>3</td>
      <td>pool</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>995</th>
      <td>21.474205</td>
      <td>168.602546</td>
      <td>70.342128</td>
      <td>0.0</td>
      <td>2</td>
      <td>5</td>
      <td>target</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>10995</td>
    </tr>
    <tr>
      <th>996</th>
      <td>40.643320</td>
      <td>188.188724</td>
      <td>61.611744</td>
      <td>0.0</td>
      <td>2</td>
      <td>4</td>
      <td>target</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>10996</td>
    </tr>
    <tr>
      <th>997</th>
      <td>29.472765</td>
      <td>161.408162</td>
      <td>57.214095</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>target</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>10997</td>
    </tr>
    <tr>
      <th>998</th>
      <td>41.291949</td>
      <td>150.968833</td>
      <td>91.270798</td>
      <td>0.0</td>
      <td>0</td>
      <td>3</td>
      <td>target</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10998</td>
    </tr>
    <tr>
      <th>999</th>
      <td>67.530294</td>
      <td>155.124741</td>
      <td>56.196505</td>
      <td>1.0</td>
      <td>0</td>
      <td>1</td>
      <td>target</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10999</td>
    </tr>
  </tbody>
</table>
<p>11000 rows × 12 columns</p>
</div></div>
</div>
<section id="Optimize-Beta-(Mean-Absolute-SMD)">
<h2>Optimize Beta (Mean Absolute SMD)<a class="headerlink" href="#Optimize-Beta-(Mean-Absolute-SMD)" title="Permalink to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">objective</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">BetaBalance</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">matcher</span> <span class="o">=</span> <span class="n">matcher_beta</span> <span class="o">=</span> <span class="n">GeneticMatcher</span><span class="p">(</span>
    <span class="n">matching_data</span> <span class="o">=</span> <span class="n">m</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span><span class="p">,</span>
    <span class="n">log_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_generations</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span>
    <span class="n">time_limit</span> <span class="o">=</span> <span class="n">time_limit</span>
<span class="p">)</span>
<span class="n">matcher</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [matcher.py:127] cpu
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;objective&#39;: &#39;beta&#39;,
 &#39;candidate_population_size&#39;: 1000,
 &#39;n_candidate_populations&#39;: 1024,
 &#39;n_keep_best&#39;: 256,
 &#39;n_voting_populations&#39;: 256,
 &#39;n_mutation&#39;: 256,
 &#39;n_generations&#39;: 5000,
 &#39;n_iter_no_change&#39;: 100,
 &#39;time_limit&#39;: 300,
 &#39;max_batch_size_gb&#39;: 2,
 &#39;seed&#39;: 1234,
 &#39;verbose&#39;: True,
 &#39;log_every&#39;: 1000,
 &#39;initialization&#39;: {&#39;benchmarks&#39;: {&#39;propensity&#39;: &#39;include&#39;},
  &#39;sampling&#39;: {&#39;propensity&#39;: 1.0, &#39;uniform&#39;: 1.0}}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matcher_beta</span><span class="o">.</span><span class="n">match</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [initialization.py:34] Optimizing balance with genetic algorithm ...
INFO [initialization.py:35] Initial balance scores:
INFO [initialization.py:40]     beta:   0.233
INFO [initialization.py:41] Initializing candidate populations ...
INFO [initialization.py:89] Computing PROPENSITY 1-1 matching method ...
INFO [matcher.py:181] Training model SGDClassifier (iter 1/50, 0.003 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: SGDClassifier
INFO [matcher.py:140]   * alpha: 1.5074398973827778
INFO [matcher.py:140]   * class_weight: None
INFO [matcher.py:140]   * early_stopping: True
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * loss: log_loss
INFO [matcher.py:140]   * max_iter: 1500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:141]   Score (beta): 0.0525
INFO [matcher.py:142]   Solution time: 0.008 min
INFO [matcher.py:181] Training model LogisticRegression (iter 2/50, 0.009 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.05835496346821341
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta): 0.0291
INFO [matcher.py:142]   Solution time: 0.014 min
INFO [matcher.py:181] Training model LogisticRegression (iter 3/50, 0.014 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 4/50, 0.074 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 5/50, 0.079 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 6/50, 0.136 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 7/50, 0.141 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 8/50, 0.146 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 9/50, 0.150 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 10/50, 0.193 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 11/50, 0.198 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 12/50, 0.203 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 13/50, 0.208 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 14/50, 0.213 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 15/50, 0.217 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 16/50, 0.221 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 17/50, 0.226 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 18/50, 0.231 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 2.390557089970641
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta): 0.0289
INFO [matcher.py:142]   Solution time: 0.238 min
INFO [matcher.py:181] Training model LogisticRegression (iter 19/50, 0.239 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 20/50, 0.274 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 21/50, 0.280 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 22/50, 0.286 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 23/50, 0.295 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 24/50, 0.299 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 25/50, 0.304 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 26/50, 0.308 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.26994114136168157
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta): 0.0288
INFO [matcher.py:142]   Solution time: 0.314 min
INFO [matcher.py:181] Training model LogisticRegression (iter 27/50, 0.314 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 28/50, 0.321 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 29/50, 0.372 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 30/50, 0.375 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 31/50, 0.384 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 32/50, 0.390 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 33/50, 0.395 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 34/50, 0.400 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 35/50, 0.404 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 36/50, 0.471 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 37/50, 0.486 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.5868985298319502
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta): 0.0249
INFO [matcher.py:142]   Solution time: 0.555 min
INFO [matcher.py:181] Training model SGDClassifier (iter 38/50, 0.556 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 39/50, 0.561 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 40/50, 0.566 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 41/50, 0.572 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 42/50, 0.577 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 43/50, 0.617 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 44/50, 0.682 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 45/50, 0.687 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 46/50, 0.694 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 47/50, 0.756 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 48/50, 0.819 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 49/50, 0.824 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 50/50, 0.828 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.5868985298319502
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta): 0.0249
INFO [matcher.py:142]   Solution time: 0.555 min
INFO [initialization.py:69]     beta:   0.025
INFO [initialization.py:74]     Included in initial population.

INFO [initialization.py:135] Sampling 512 candidate populations according to PROPENSITY distribution ...

INFO [initialization.py:135] Sampling 511 candidate populations according to UNIFORM distribution ...

INFO [logger.py:38] Generation 0
INFO [logger.py:39]     remaining patients: 10000
INFO [logger.py:40]     elapsed time: 0.89 min
INFO [logger.py:49]     best beta: 0.02494      worst beta: 0.25118
INFO [matcher.py:213] Time limit exceeded. Stopping.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
        <b>Headers Numeric: </b><br>
        ['age', 'height', 'weight']<br><br>
        <b>Headers Categoric: </b><br>
        ['gender', 'haircolor', 'country', 'binary_0', 'binary_1', 'binary_2', 'binary_3'] <br><br>
        <b>Populations</b> <br>
        ['pool', 'target'] <br>
        <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>height</th>
      <th>weight</th>
      <th>gender</th>
      <th>haircolor</th>
      <th>country</th>
      <th>population</th>
      <th>binary_0</th>
      <th>binary_1</th>
      <th>binary_2</th>
      <th>binary_3</th>
      <th>patient_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>55.261578</td>
      <td>139.396134</td>
      <td>94.438359</td>
      <td>0.0</td>
      <td>2</td>
      <td>2</td>
      <td>target</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63.113091</td>
      <td>165.563337</td>
      <td>67.433016</td>
      <td>1.0</td>
      <td>2</td>
      <td>2</td>
      <td>target</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>10001</td>
    </tr>
    <tr>
      <th>2</th>
      <td>58.232216</td>
      <td>160.859857</td>
      <td>71.915385</td>
      <td>1.0</td>
      <td>0</td>
      <td>2</td>
      <td>target</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10002</td>
    </tr>
    <tr>
      <th>3</th>
      <td>58.996941</td>
      <td>140.357415</td>
      <td>115.606615</td>
      <td>1.0</td>
      <td>0</td>
      <td>3</td>
      <td>target</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>10003</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36.850195</td>
      <td>189.983706</td>
      <td>53.000581</td>
      <td>0.0</td>
      <td>2</td>
      <td>5</td>
      <td>target</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10004</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1112</th>
      <td>41.629635</td>
      <td>184.070238</td>
      <td>89.104386</td>
      <td>1.0</td>
      <td>1</td>
      <td>5</td>
      <td>pool</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1112</td>
    </tr>
    <tr>
      <th>3201</th>
      <td>65.983796</td>
      <td>143.585419</td>
      <td>85.288685</td>
      <td>0.0</td>
      <td>2</td>
      <td>3</td>
      <td>pool</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>3201</td>
    </tr>
    <tr>
      <th>8918</th>
      <td>51.343352</td>
      <td>147.636272</td>
      <td>71.272276</td>
      <td>0.0</td>
      <td>2</td>
      <td>2</td>
      <td>pool</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>8918</td>
    </tr>
    <tr>
      <th>106</th>
      <td>57.306919</td>
      <td>177.491110</td>
      <td>89.600459</td>
      <td>1.0</td>
      <td>1</td>
      <td>2</td>
      <td>pool</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>106</td>
    </tr>
    <tr>
      <th>4489</th>
      <td>41.355307</td>
      <td>135.700502</td>
      <td>65.057679</td>
      <td>0.0</td>
      <td>2</td>
      <td>4</td>
      <td>pool</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>4489</td>
    </tr>
  </tbody>
</table>
<p>2000 rows × 12 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">match</span> <span class="o">=</span> <span class="n">matcher_beta</span><span class="o">.</span><span class="n">get_best_match</span><span class="p">()</span>
<span class="n">m_data</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s1">&#39;pool&#39;</span><span class="p">)</span>
<span class="n">m_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">m_data</span><span class="p">[</span><span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; (prematch)&#39;</span>
<span class="k">match</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m_data</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_per_feature_loss</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">debin</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_numeric_features</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pool (prematch)&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_categoric_features</span><span class="p">(</span><span class="n">match</span><span class="p">,</span>  <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pool (prematch)&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_6_0.png" src="../_images/demos_ea_matcher_6_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_6_1.png" src="../_images/demos_ea_matcher_6_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_6_2.png" src="../_images/demos_ea_matcher_6_2.png" />
</div>
</div>
</section>
<section id="Optimize-Beta^2">
<h2>Optimize Beta^2<a class="headerlink" href="#Optimize-Beta^2" title="Permalink to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">objective</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">=</span> <span class="n">BetaSquaredBalance</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">matcher</span> <span class="o">=</span> <span class="n">matcher_beta2</span> <span class="o">=</span> <span class="n">GeneticMatcher</span><span class="p">(</span>
    <span class="n">matching_data</span> <span class="o">=</span> <span class="n">m</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span><span class="p">,</span>
    <span class="n">log_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_generations</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span>
    <span class="n">time_limit</span> <span class="o">=</span> <span class="n">time_limit</span>
<span class="p">)</span>
<span class="n">matcher</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [matcher.py:127] cpu
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;objective&#39;: &#39;beta_squared&#39;,
 &#39;candidate_population_size&#39;: 1000,
 &#39;n_candidate_populations&#39;: 1024,
 &#39;n_keep_best&#39;: 256,
 &#39;n_voting_populations&#39;: 256,
 &#39;n_mutation&#39;: 256,
 &#39;n_generations&#39;: 5000,
 &#39;n_iter_no_change&#39;: 100,
 &#39;time_limit&#39;: 300,
 &#39;max_batch_size_gb&#39;: 2,
 &#39;seed&#39;: 1234,
 &#39;verbose&#39;: True,
 &#39;log_every&#39;: 1000,
 &#39;initialization&#39;: {&#39;benchmarks&#39;: {&#39;propensity&#39;: &#39;include&#39;},
  &#39;sampling&#39;: {&#39;propensity&#39;: 1.0, &#39;uniform&#39;: 1.0}}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">match</span> <span class="o">=</span> <span class="n">matcher</span><span class="o">.</span><span class="n">match</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [initialization.py:34] Optimizing balance with genetic algorithm ...
INFO [initialization.py:35] Initial balance scores:
INFO [initialization.py:40]     beta_squared:   0.263
INFO [initialization.py:41] Initializing candidate populations ...
INFO [initialization.py:89] Computing PROPENSITY 1-1 matching method ...
INFO [matcher.py:181] Training model SGDClassifier (iter 1/50, 0.001 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: SGDClassifier
INFO [matcher.py:140]   * alpha: 1.5074398973827778
INFO [matcher.py:140]   * class_weight: None
INFO [matcher.py:140]   * early_stopping: True
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * loss: log_loss
INFO [matcher.py:140]   * max_iter: 1500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:141]   Score (beta_squared): 0.0603
INFO [matcher.py:142]   Solution time: 0.005 min
INFO [matcher.py:181] Training model LogisticRegression (iter 2/50, 0.005 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.05835496346821341
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta_squared): 0.0374
INFO [matcher.py:142]   Solution time: 0.009 min
INFO [matcher.py:181] Training model LogisticRegression (iter 3/50, 0.010 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 16.16555309446664
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta_squared): 0.0357
INFO [matcher.py:142]   Solution time: 0.062 min
INFO [matcher.py:181] Training model SGDClassifier (iter 4/50, 0.062 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 5/50, 0.066 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 54.02072493419675
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta_squared): 0.0347
INFO [matcher.py:142]   Solution time: 0.113 min
INFO [matcher.py:181] Training model LogisticRegression (iter 6/50, 0.113 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 7/50, 0.119 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 8/50, 0.125 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 9/50, 0.129 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 10/50, 0.165 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 11/50, 0.170 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 12/50, 0.175 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 13/50, 0.179 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 14/50, 0.183 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 15/50, 0.187 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 16/50, 0.190 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 17/50, 0.194 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 18/50, 0.198 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 19/50, 0.203 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 20/50, 0.227 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 21/50, 0.231 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 22/50, 0.235 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 23/50, 0.238 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 24/50, 0.241 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 25/50, 0.247 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 26/50, 0.251 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 27/50, 0.256 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 28/50, 0.262 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 29/50, 0.303 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 30/50, 0.307 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 31/50, 0.313 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 32/50, 0.317 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 33/50, 0.321 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 34/50, 0.325 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 35/50, 0.327 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 36/50, 0.378 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 37/50, 0.389 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.5868985298319502
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta_squared): 0.0311
INFO [matcher.py:142]   Solution time: 0.436 min
INFO [matcher.py:181] Training model SGDClassifier (iter 38/50, 0.437 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 39/50, 0.440 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 40/50, 0.443 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 41/50, 0.446 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 42/50, 0.449 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 43/50, 0.473 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 44/50, 0.516 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 45/50, 0.518 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 46/50, 0.522 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 47/50, 0.567 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 48/50, 0.611 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 49/50, 0.613 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 50/50, 0.616 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.5868985298319502
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (beta_squared): 0.0311
INFO [matcher.py:142]   Solution time: 0.436 min
INFO [initialization.py:69]     beta_squared:   0.031
INFO [initialization.py:74]     Included in initial population.

INFO [initialization.py:135] Sampling 512 candidate populations according to PROPENSITY distribution ...

INFO [initialization.py:135] Sampling 511 candidate populations according to UNIFORM distribution ...

INFO [logger.py:38] Generation 0
INFO [logger.py:39]     remaining patients: 10000
INFO [logger.py:40]     elapsed time: 0.65 min
INFO [logger.py:49]     best beta_squared: 0.03106      worst beta_squared: 0.28163
INFO [matcher.py:213] Time limit exceeded. Stopping.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">match</span> <span class="o">=</span> <span class="n">matcher_beta2</span><span class="o">.</span><span class="n">get_best_match</span><span class="p">()</span>
<span class="n">m_data</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s1">&#39;pool&#39;</span><span class="p">)</span>
<span class="n">m_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">m_data</span><span class="p">[</span><span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; (prematch)&#39;</span>
<span class="k">match</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m_data</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_per_feature_loss</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">debin</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_numeric_features</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pool (prematch)&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_categoric_features</span><span class="p">(</span><span class="n">match</span><span class="p">,</span>  <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pool (prematch)&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_10_0.png" src="../_images/demos_ea_matcher_10_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_10_1.png" src="../_images/demos_ea_matcher_10_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_10_2.png" src="../_images/demos_ea_matcher_10_2.png" />
</div>
</div>
</section>
<section id="Optimize-Gamma-(Area-Between-CDFs)">
<h2>Optimize Gamma (Area Between CDFs)<a class="headerlink" href="#Optimize-Gamma-(Area-Between-CDFs)" title="Permalink to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">objective</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">=</span> <span class="n">GammaBalance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">feature_weights</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;age&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>
<span class="n">matcher</span> <span class="o">=</span> <span class="n">matcher_gamma</span> <span class="o">=</span> <span class="n">GeneticMatcher</span><span class="p">(</span>
    <span class="n">matching_data</span> <span class="o">=</span> <span class="n">m</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span><span class="p">,</span>
    <span class="n">log_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_generations</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span>
    <span class="n">time_limit</span> <span class="o">=</span> <span class="n">time_limit</span>
<span class="p">)</span>
<span class="n">matcher</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [preprocess.py:338] Discretized age with bins [18.05, 27.54, 37.04, 46.53, 56.02, 65.51, 75.0].
INFO [preprocess.py:338] Discretized height with bins [125.01, 136.68, 148.34, 160.01, 171.67, 183.34, 195.0].
INFO [preprocess.py:338] Discretized weight with bins [50.0, 61.67, 73.33, 85.0, 96.66, 108.33, 120.0].
INFO [matcher.py:127] cpu
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;objective&#39;: &#39;gamma&#39;,
 &#39;candidate_population_size&#39;: 1000,
 &#39;n_candidate_populations&#39;: 1024,
 &#39;n_keep_best&#39;: 256,
 &#39;n_voting_populations&#39;: 256,
 &#39;n_mutation&#39;: 256,
 &#39;n_generations&#39;: 5000,
 &#39;n_iter_no_change&#39;: 100,
 &#39;time_limit&#39;: 300,
 &#39;max_batch_size_gb&#39;: 2,
 &#39;seed&#39;: 1234,
 &#39;verbose&#39;: True,
 &#39;log_every&#39;: 1000,
 &#39;initialization&#39;: {&#39;benchmarks&#39;: {&#39;propensity&#39;: &#39;include&#39;},
  &#39;sampling&#39;: {&#39;propensity&#39;: 1.0, &#39;uniform&#39;: 1.0}}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">match</span> <span class="o">=</span> <span class="n">matcher</span><span class="o">.</span><span class="n">match</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO [initialization.py:34] Optimizing balance with genetic algorithm ...
INFO [initialization.py:35] Initial balance scores:
INFO [initialization.py:40]     gamma:  0.217
INFO [initialization.py:41] Initializing candidate populations ...
INFO [initialization.py:89] Computing PROPENSITY 1-1 matching method ...
INFO [matcher.py:181] Training model SGDClassifier (iter 1/50, 0.001 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: SGDClassifier
INFO [matcher.py:140]   * alpha: 1.5074398973827778
INFO [matcher.py:140]   * class_weight: None
INFO [matcher.py:140]   * early_stopping: True
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * loss: log_loss
INFO [matcher.py:140]   * max_iter: 1500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:141]   Score (gamma): 0.1083
INFO [matcher.py:142]   Solution time: 0.005 min
INFO [matcher.py:181] Training model LogisticRegression (iter 2/50, 0.005 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 0.05835496346821341
INFO [matcher.py:140]   * fit_intercept: True
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (gamma): 0.0391
INFO [matcher.py:142]   Solution time: 0.009 min
INFO [matcher.py:181] Training model LogisticRegression (iter 3/50, 0.010 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 16.16555309446664
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l1
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (gamma): 0.0376
INFO [matcher.py:142]   Solution time: 0.067 min
INFO [matcher.py:181] Training model SGDClassifier (iter 4/50, 0.067 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 5/50, 0.072 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 54.02072493419675
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (gamma): 0.0337
INFO [matcher.py:142]   Solution time: 0.118 min
INFO [matcher.py:181] Training model LogisticRegression (iter 6/50, 0.119 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 7/50, 0.125 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 8/50, 0.129 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 9/50, 0.132 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 13.179630432958684
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (gamma): 0.0269
INFO [matcher.py:142]   Solution time: 0.180 min
INFO [matcher.py:181] Training model LogisticRegression (iter 10/50, 0.180 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 11/50, 0.185 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 12/50, 0.190 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 13/50, 0.194 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 14/50, 0.197 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 15/50, 0.201 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 16/50, 0.205 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 17/50, 0.209 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 18/50, 0.213 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 19/50, 0.224 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 20/50, 0.274 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 21/50, 0.278 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 22/50, 0.282 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 23/50, 0.286 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 24/50, 0.289 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 25/50, 0.297 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 26/50, 0.301 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 27/50, 0.308 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 28/50, 0.313 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 29/50, 0.374 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 30/50, 0.378 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 31/50, 0.387 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 32/50, 0.391 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 33/50, 0.396 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 34/50, 0.399 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 35/50, 0.402 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 36/50, 0.465 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 37/50, 0.488 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 38/50, 0.549 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 39/50, 0.552 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 40/50, 0.555 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 41/50, 0.561 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 42/50, 0.564 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 43/50, 0.610 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 44/50, 0.671 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 45/50, 0.674 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 46/50, 0.678 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model LogisticRegression (iter 47/50, 0.732 min) ...
/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
INFO [matcher.py:181] Training model SGDClassifier (iter 48/50, 0.789 min) ...
INFO [matcher.py:181] Training model SGDClassifier (iter 49/50, 0.792 min) ...
INFO [matcher.py:181] Training model LogisticRegression (iter 50/50, 0.796 min) ...
INFO [matcher.py:137] Best propensity score match found:
INFO [matcher.py:138]   Model: LogisticRegression
INFO [matcher.py:140]   * C: 13.179630432958684
INFO [matcher.py:140]   * fit_intercept: False
INFO [matcher.py:140]   * max_iter: 500
INFO [matcher.py:140]   * penalty: l2
INFO [matcher.py:140]   * solver: saga
INFO [matcher.py:141]   Score (gamma): 0.0269
INFO [matcher.py:142]   Solution time: 0.180 min
INFO [initialization.py:69]     gamma:  0.027
INFO [initialization.py:74]     Included in initial population.

INFO [initialization.py:135] Sampling 512 candidate populations according to PROPENSITY distribution ...

INFO [initialization.py:135] Sampling 511 candidate populations according to UNIFORM distribution ...

INFO [logger.py:38] Generation 0
INFO [logger.py:39]     remaining patients: 10000
INFO [logger.py:40]     elapsed time: 0.83 min
INFO [logger.py:49]     best gamma: 0.02688     worst gamma: 0.23595
INFO [matcher.py:213] Time limit exceeded. Stopping.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">match</span> <span class="o">=</span> <span class="n">matcher</span><span class="o">.</span><span class="n">get_best_match</span><span class="p">()</span>
<span class="n">m_data</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s1">&#39;pool&#39;</span><span class="p">)</span>
<span class="n">m_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">m_data</span><span class="p">[</span><span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; (prematch)&#39;</span>
<span class="k">match</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m_data</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_per_feature_loss</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">debin</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_numeric_features</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pool (prematch)&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_categoric_features</span><span class="p">(</span><span class="n">match</span><span class="p">,</span>  <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pool (prematch)&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_14_0.png" src="../_images/demos_ea_matcher_14_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_14_1.png" src="../_images/demos_ea_matcher_14_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/demos_ea_matcher_14_2.png" src="../_images/demos_ea_matcher_14_2.png" />
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ps_matcher.html" class="btn btn-neutral float-left" title="Propensity Score Matcher" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lp_matcher.html" class="btn btn-neutral float-right" title="Constraint Satisfaction Matcher" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 - Bayer AG - Stephen Privitera, Hooman Sedghamiz, Alex Hartenstein.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>